{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quesiton 1 - Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19882,\n",
       " 7697,\n",
       " 14041,\n",
       " 31273,\n",
       " 31960,\n",
       " 12913,\n",
       " 22505,\n",
       " 1677,\n",
       " 32226,\n",
       " 1147,\n",
       " 712,\n",
       " 11570,\n",
       " 21662,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 17066,\n",
       " 2893,\n",
       " 25219,\n",
       " 25141,\n",
       " 12738,\n",
       " 14097,\n",
       " 6158,\n",
       " 7097,\n",
       " 1015,\n",
       " 31498,\n",
       " 24274,\n",
       " 22319,\n",
       " 19654,\n",
       " 31498,\n",
       " 22599,\n",
       " 20384,\n",
       " 18159,\n",
       " 28151,\n",
       " 22505,\n",
       " 24188,\n",
       " 4203,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 5246,\n",
       " 12758,\n",
       " 2668,\n",
       " 22505,\n",
       " 13003,\n",
       " 14219,\n",
       " 6300,\n",
       " 27119,\n",
       " 3054,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 12892,\n",
       " 29891,\n",
       " 21382,\n",
       " 613,\n",
       " 17066,\n",
       " 13003,\n",
       " 1147,\n",
       " 26140,\n",
       " 31498,\n",
       " 9065,\n",
       " 31273,\n",
       " 31960,\n",
       " 21058,\n",
       " 712,\n",
       " 18108,\n",
       " 5009,\n",
       " 32818,\n",
       " 11570,\n",
       " 21662,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 22505,\n",
       " 5064,\n",
       " 17066,\n",
       " 2893,\n",
       " 13265,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 5702,\n",
       " 7697,\n",
       " 17345,\n",
       " 1144,\n",
       " 16001,\n",
       " 31273,\n",
       " 31976,\n",
       " 13003,\n",
       " 16846,\n",
       " 32014,\n",
       " 1677,\n",
       " 32226,\n",
       " 1147,\n",
       " 22505,\n",
       " 14650,\n",
       " 32226,\n",
       " 27238,\n",
       " 21382,\n",
       " 6300,\n",
       " 21366,\n",
       " 6300,\n",
       " 22505,\n",
       " 28179,\n",
       " 13064,\n",
       " 20022,\n",
       " 20342,\n",
       " 23145,\n",
       " 32226,\n",
       " 28963,\n",
       " 29463,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 18862,\n",
       " 11281,\n",
       " 32226,\n",
       " 23359,\n",
       " 4868,\n",
       " 47,\n",
       " 13265,\n",
       " 27372,\n",
       " 28599,\n",
       " 16312,\n",
       " 22352,\n",
       " 31498,\n",
       " 31273,\n",
       " 9223,\n",
       " 28179,\n",
       " 23140,\n",
       " 33028,\n",
       " 28963,\n",
       " 11872,\n",
       " 712,\n",
       " 19851,\n",
       " 12137,\n",
       " 23244,\n",
       " 31498,\n",
       " 13003,\n",
       " 30660,\n",
       " 915,\n",
       " 13003,\n",
       " 19904,\n",
       " 29676,\n",
       " 11874,\n",
       " 22042,\n",
       " 9791,\n",
       " 6050,\n",
       " 25749,\n",
       " 31498,\n",
       " 22505,\n",
       " 28179,\n",
       " 11705,\n",
       " 21633,\n",
       " 32834,\n",
       " 25238,\n",
       " 32226,\n",
       " 13003,\n",
       " 25238,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 31273,\n",
       " 292,\n",
       " 13003,\n",
       " 16785,\n",
       " 28963,\n",
       " 11872,\n",
       " 27899,\n",
       " 242,\n",
       " 1804,\n",
       " 28179,\n",
       " 1050,\n",
       " 915,\n",
       " 13202,\n",
       " 15610,\n",
       " 24110,\n",
       " 31498,\n",
       " 3888,\n",
       " 28963,\n",
       " 8961,\n",
       " 31498,\n",
       " 14742,\n",
       " 30101,\n",
       " 22490,\n",
       " 28179,\n",
       " 3802,\n",
       " 31498,\n",
       " 32277,\n",
       " 30101,\n",
       " 16468,\n",
       " 28179,\n",
       " 3101,\n",
       " 19163,\n",
       " 23381,\n",
       " 33169,\n",
       " 14436,\n",
       " 8961,\n",
       " 31498,\n",
       " 4618,\n",
       " 915,\n",
       " 24307,\n",
       " 7953,\n",
       " 10144,\n",
       " 26959,\n",
       " 28963,\n",
       " 33707,\n",
       " 7713,\n",
       " 27833,\n",
       " 13003,\n",
       " 25238,\n",
       " 31043,\n",
       " 15552,\n",
       " 6395,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 13459,\n",
       " 32277,\n",
       " 712,\n",
       " 13003,\n",
       " 25238,\n",
       " 21662,\n",
       " 15552,\n",
       " 28666,\n",
       " 242,\n",
       " 32226,\n",
       " 29705,\n",
       " 13003,\n",
       " 2268,\n",
       " 6306,\n",
       " 32226,\n",
       " 26843,\n",
       " 17066,\n",
       " 19830,\n",
       " 15610,\n",
       " 27429,\n",
       " 9524,\n",
       " 12151,\n",
       " 14302,\n",
       " 10732,\n",
       " 22505,\n",
       " 28179,\n",
       " 9119,\n",
       " 712,\n",
       " 25338,\n",
       " 31498,\n",
       " 11394,\n",
       " 31498,\n",
       " 12410,\n",
       " 32226,\n",
       " 22335,\n",
       " 13202,\n",
       " 27626,\n",
       " 17066,\n",
       " 32896,\n",
       " 13003,\n",
       " 27508,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 30753,\n",
       " 13931,\n",
       " 31387,\n",
       " 12823,\n",
       " 11765,\n",
       " 27895,\n",
       " 7224,\n",
       " 13003,\n",
       " 5966,\n",
       " 18418,\n",
       " 915,\n",
       " 22702,\n",
       " 27062,\n",
       " 13202,\n",
       " 25643,\n",
       " 7121,\n",
       " 28532,\n",
       " 32216,\n",
       " 22505,\n",
       " 6730,\n",
       " 712,\n",
       " 16883,\n",
       " 4201,\n",
       " 22505,\n",
       " 21178,\n",
       " 6631,\n",
       " 25238,\n",
       " 24808,\n",
       " 15759,\n",
       " 32153,\n",
       " 32849,\n",
       " 28864,\n",
       " 5784,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 2345,\n",
       " 31273,\n",
       " 31985,\n",
       " 9303,\n",
       " 58,\n",
       " 4201,\n",
       " 22505,\n",
       " 24887,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 24203,\n",
       " 4163,\n",
       " 2037,\n",
       " 712,\n",
       " 28532,\n",
       " 31498,\n",
       " 31273,\n",
       " 31207,\n",
       " 13960,\n",
       " 712,\n",
       " 11570,\n",
       " 21662,\n",
       " 28992,\n",
       " 28179,\n",
       " 33580,\n",
       " 17066,\n",
       " 14230,\n",
       " 4868,\n",
       " 29772,\n",
       " 5584,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 12428,\n",
       " 28355,\n",
       " 32141,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 31465,\n",
       " 30606,\n",
       " 13931,\n",
       " 17158,\n",
       " 7057,\n",
       " 10742,\n",
       " 17066,\n",
       " 29180,\n",
       " 29718,\n",
       " 31273,\n",
       " 26959,\n",
       " 22505,\n",
       " 28179,\n",
       " 16418,\n",
       " 1677,\n",
       " 28682,\n",
       " 28963,\n",
       " 4868,\n",
       " 20342,\n",
       " 16800,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 7840,\n",
       " 3529,\n",
       " 31498,\n",
       " 32226,\n",
       " 7297,\n",
       " 29718,\n",
       " 31273,\n",
       " 29997,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 17892,\n",
       " 33524,\n",
       " 26878,\n",
       " 712,\n",
       " 30606,\n",
       " 32141,\n",
       " 30808,\n",
       " 25238,\n",
       " 1936,\n",
       " 613,\n",
       " 17066,\n",
       " 13003,\n",
       " 26140,\n",
       " 31498,\n",
       " 31465,\n",
       " 30606,\n",
       " 32449,\n",
       " 2563,\n",
       " 11549,\n",
       " 9119,\n",
       " 30606,\n",
       " 1051,\n",
       " 7532,\n",
       " 30007,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 12596,\n",
       " 28963,\n",
       " 13003,\n",
       " 30105,\n",
       " 8313,\n",
       " 14650,\n",
       " 5784,\n",
       " 22505,\n",
       " 22319,\n",
       " 1147,\n",
       " 31498,\n",
       " 31273,\n",
       " 21058,\n",
       " 29102,\n",
       " 8022,\n",
       " 915,\n",
       " 28179,\n",
       " 3802,\n",
       " 13459,\n",
       " 18159,\n",
       " 25238,\n",
       " 613,\n",
       " 17066,\n",
       " 712,\n",
       " 30293,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 20526,\n",
       " 25291,\n",
       " 712,\n",
       " 30606,\n",
       " 9835,\n",
       " 28179,\n",
       " 3802,\n",
       " 22505,\n",
       " 25238,\n",
       " 2037,\n",
       " 13003,\n",
       " 26140,\n",
       " 31498,\n",
       " 22702,\n",
       " 32141,\n",
       " 19044,\n",
       " 27119,\n",
       " 31665,\n",
       " 6147,\n",
       " 6631,\n",
       " 13003,\n",
       " 31542,\n",
       " 17066,\n",
       " 2893,\n",
       " 29718,\n",
       " 31273,\n",
       " 26959,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 23651,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 31498,\n",
       " 28953,\n",
       " 19859,\n",
       " 31498,\n",
       " 27429,\n",
       " 32141,\n",
       " 15336,\n",
       " 31098,\n",
       " 6631,\n",
       " 7057,\n",
       " 11159,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 19500,\n",
       " 21336,\n",
       " 19970,\n",
       " 17066,\n",
       " 30238,\n",
       " 1936,\n",
       " 613,\n",
       " 17066,\n",
       " 13003,\n",
       " 26140,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 31587,\n",
       " 28321,\n",
       " 8022,\n",
       " 915,\n",
       " 28179,\n",
       " 3802,\n",
       " 25947,\n",
       " 29718,\n",
       " 29997,\n",
       " 31273,\n",
       " 28375,\n",
       " 33707,\n",
       " 8304,\n",
       " 13003,\n",
       " 21592,\n",
       " 22505,\n",
       " 25358,\n",
       " 1147,\n",
       " 31273,\n",
       " 26959,\n",
       " 27119,\n",
       " 27062,\n",
       " 18212,\n",
       " 20030,\n",
       " 13459,\n",
       " 17066,\n",
       " 25291,\n",
       " 31498,\n",
       " 32277,\n",
       " 26959,\n",
       " 11570,\n",
       " 21662,\n",
       " 3666,\n",
       " 17066,\n",
       " 3802,\n",
       " 21257,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 20493,\n",
       " 26959,\n",
       " 2037,\n",
       " 31498,\n",
       " 33524,\n",
       " 21336,\n",
       " 11570,\n",
       " 32141,\n",
       " 3666,\n",
       " 17066,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 31465,\n",
       " 33524,\n",
       " 21336,\n",
       " 30606,\n",
       " 15645,\n",
       " 27119,\n",
       " 6300,\n",
       " 16147,\n",
       " 33203,\n",
       " 29718,\n",
       " 31273,\n",
       " 26959,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 10615,\n",
       " 12653,\n",
       " 20030,\n",
       " 32226,\n",
       " 9950,\n",
       " 12653,\n",
       " 20030,\n",
       " 3050,\n",
       " 17066,\n",
       " 27292,\n",
       " 17066,\n",
       " 25291,\n",
       " 31498,\n",
       " 32277,\n",
       " 33524,\n",
       " 21336,\n",
       " 30606,\n",
       " 32141,\n",
       " 17158,\n",
       " 3666,\n",
       " 17066,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 33524,\n",
       " 21336,\n",
       " 30606,\n",
       " 15645,\n",
       " 712,\n",
       " 6300,\n",
       " 28179,\n",
       " 764,\n",
       " 24237,\n",
       " 28179,\n",
       " 33774,\n",
       " 10415,\n",
       " 31498,\n",
       " 32226,\n",
       " 33524,\n",
       " 21336,\n",
       " 27970,\n",
       " 17602,\n",
       " 6631,\n",
       " 13003,\n",
       " 21518,\n",
       " 14976,\n",
       " 11770,\n",
       " 23381,\n",
       " 33169,\n",
       " 15003,\n",
       " 28963,\n",
       " 13003,\n",
       " 23821,\n",
       " 1734,\n",
       " 31708,\n",
       " 22505,\n",
       " 23361,\n",
       " 1147,\n",
       " 31498,\n",
       " 31273,\n",
       " 23105,\n",
       " 4868,\n",
       " 25335,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 20526,\n",
       " 30238,\n",
       " 17066,\n",
       " 21336,\n",
       " 712,\n",
       " 13003,\n",
       " 11281,\n",
       " 8109,\n",
       " 22239,\n",
       " 17066,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 18159,\n",
       " 25238,\n",
       " 29718,\n",
       " 26959,\n",
       " 31273,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 20526,\n",
       " 21336,\n",
       " 1512,\n",
       " 28179,\n",
       " 9359,\n",
       " 10719,\n",
       " 21263,\n",
       " 3050,\n",
       " 17066,\n",
       " 32977,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 21581,\n",
       " 33524,\n",
       " 21336,\n",
       " 20843,\n",
       " 17066,\n",
       " 32977,\n",
       " 712,\n",
       " 6631,\n",
       " 33774,\n",
       " 20508,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 30753,\n",
       " 31976,\n",
       " 13003,\n",
       " 6880,\n",
       " 25335,\n",
       " 28963,\n",
       " 33707,\n",
       " 8669,\n",
       " 18159,\n",
       " 30441,\n",
       " 27061,\n",
       " 712,\n",
       " 31337,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 30244,\n",
       " 19839,\n",
       " 3428,\n",
       " 31498,\n",
       " 11570,\n",
       " 32141,\n",
       " 179,\n",
       " 28179,\n",
       " 3802,\n",
       " 29718,\n",
       " 31273,\n",
       " 26959,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 24590,\n",
       " 26498,\n",
       " 1463,\n",
       " 11989,\n",
       " 8315,\n",
       " 31665,\n",
       " 21263,\n",
       " 26498,\n",
       " 31498,\n",
       " 242,\n",
       " 13003,\n",
       " 9119,\n",
       " 31498,\n",
       " 20376,\n",
       " 6515,\n",
       " 28599,\n",
       " 300,\n",
       " 31665,\n",
       " 29230,\n",
       " 31498,\n",
       " 32277,\n",
       " 242,\n",
       " 712,\n",
       " 18635,\n",
       " 11543,\n",
       " 19703,\n",
       " 11770,\n",
       " 23381,\n",
       " 33169,\n",
       " 12615,\n",
       " 33524,\n",
       " 21336,\n",
       " 712,\n",
       " 30606,\n",
       " 21662,\n",
       " 32977,\n",
       " 27119,\n",
       " 29718,\n",
       " 31273,\n",
       " 26634,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 20526,\n",
       " 32977,\n",
       " 26878,\n",
       " 30606,\n",
       " 32141,\n",
       " 32977,\n",
       " 27119,\n",
       " 7224,\n",
       " 3177,\n",
       " 30606,\n",
       " 31043,\n",
       " 27119,\n",
       " 5993,\n",
       " 13003,\n",
       " 7035,\n",
       " 915,\n",
       " 25238,\n",
       " 21596,\n",
       " 15552,\n",
       " 7224,\n",
       " 32277,\n",
       " 33524,\n",
       " 32977,\n",
       " 26878,\n",
       " 30606,\n",
       " 21662,\n",
       " 32977,\n",
       " 27119,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 14698,\n",
       " 17233,\n",
       " 712,\n",
       " 25335,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 6266,\n",
       " 13768,\n",
       " 27755,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 25362,\n",
       " 915,\n",
       " 19839,\n",
       " 28775,\n",
       " 31498,\n",
       " 6300,\n",
       " 28953,\n",
       " 19859,\n",
       " 13887,\n",
       " 23321,\n",
       " 9612,\n",
       " 27292,\n",
       " 8440,\n",
       " 3556,\n",
       " 8690,\n",
       " 7697,\n",
       " 2345,\n",
       " 14300,\n",
       " 20897,\n",
       " 18350,\n",
       " 8483,\n",
       " 31273,\n",
       " 27062,\n",
       " 19882,\n",
       " 242,\n",
       " 6312,\n",
       " 26800,\n",
       " 19882,\n",
       " 15841,\n",
       " 1752,\n",
       " 7097,\n",
       " 1015,\n",
       " 31498,\n",
       " 3515,\n",
       " 33374,\n",
       " 8119,\n",
       " 31498,\n",
       " 20983,\n",
       " 20384,\n",
       " 18159,\n",
       " 28151,\n",
       " 22505,\n",
       " 24188,\n",
       " 4203,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 5246,\n",
       " 12758,\n",
       " 2668,\n",
       " 22505,\n",
       " 13003,\n",
       " 14219,\n",
       " 6300,\n",
       " 27119,\n",
       " 3054,\n",
       " 20148,\n",
       " 19882,\n",
       " 22453,\n",
       " 14703,\n",
       " 16375,\n",
       " 24662,\n",
       " 30031,\n",
       " 915,\n",
       " 19359,\n",
       " 11677,\n",
       " 11068,\n",
       " 28541,\n",
       " 10071,\n",
       " 7202,\n",
       " 11068,\n",
       " 19882,\n",
       " 22453,\n",
       " 14703,\n",
       " 16375,\n",
       " 24662,\n",
       " 30031,\n",
       " 915,\n",
       " 19359,\n",
       " 19882,\n",
       " 33042,\n",
       " 397,\n",
       " 3570,\n",
       " 31498,\n",
       " 31273,\n",
       " 19882,\n",
       " 6543,\n",
       " 16083,\n",
       " 8109,\n",
       " 19481,\n",
       " 24237,\n",
       " 28179,\n",
       " 9718,\n",
       " 19882,\n",
       " 318,\n",
       " 21936,\n",
       " 6925,\n",
       " 30903,\n",
       " 19359,\n",
       " 19882,\n",
       " 4305,\n",
       " 19417,\n",
       " 9524,\n",
       " 31273,\n",
       " 918,\n",
       " 19018,\n",
       " 25238,\n",
       " 22513,\n",
       " 19882,\n",
       " 19882,\n",
       " 19882,\n",
       " 19882,\n",
       " 30903,\n",
       " 19359,\n",
       " 19882,\n",
       " 26268,\n",
       " 32104,\n",
       " 8262,\n",
       " 279,\n",
       " 24237,\n",
       " 19882,\n",
       " 19937,\n",
       " 23381,\n",
       " 33169,\n",
       " 19882,\n",
       " 19882,\n",
       " 19882,\n",
       " 8109,\n",
       " 13003,\n",
       " 29450,\n",
       " 13003,\n",
       " 32514,\n",
       " 13780,\n",
       " 29299,\n",
       " 22505,\n",
       " 19359,\n",
       " 31058,\n",
       " 27357,\n",
       " 13003,\n",
       " 20692,\n",
       " 16797,\n",
       " 6631,\n",
       " 13003,\n",
       " 19359,\n",
       " 19882,\n",
       " 31273,\n",
       " 30047,\n",
       " 25405,\n",
       " 28963,\n",
       " 19359,\n",
       " 19882,\n",
       " 20157,\n",
       " 29643,\n",
       " 19882,\n",
       " 28674,\n",
       " 17066,\n",
       " 6543,\n",
       " 25625,\n",
       " 26268,\n",
       " 11464,\n",
       " 27357,\n",
       " 14379,\n",
       " 29130,\n",
       " 19882,\n",
       " 27257,\n",
       " 7563,\n",
       " 17066,\n",
       " 17166,\n",
       " 28963,\n",
       " 32985,\n",
       " 19882,\n",
       " 15019,\n",
       " 9339,\n",
       " 23381,\n",
       " 33169,\n",
       " 21397,\n",
       " 21977,\n",
       " 24237,\n",
       " 13003,\n",
       " 31500,\n",
       " 19882,\n",
       " 16683,\n",
       " 26959,\n",
       " 26498,\n",
       " 19359,\n",
       " 22505,\n",
       " 3329,\n",
       " 17199,\n",
       " 32226,\n",
       " 19882,\n",
       " 28179,\n",
       " 9718,\n",
       " 10148,\n",
       " 8308,\n",
       " 6631,\n",
       " 13202,\n",
       " 12603,\n",
       " 13921,\n",
       " 19882,\n",
       " 26800,\n",
       " 19882,\n",
       " 8109,\n",
       " 28179,\n",
       " 15044,\n",
       " 10306,\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data to list\n",
    "def turnToList(string):  \n",
    "    f = open(string, 'r')\n",
    "    x = f.readlines()\n",
    "    #print(x)\n",
    "    articleVocab = x[0]\n",
    "    ls = articleVocab.split(\"', '\")\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = turnToList(\"Data/group1.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def makeBatches(data,batch_size):\n",
    "    cuts = len(data)/batch_size\n",
    "    cuts = math.ceil(cuts)\n",
    "    final_list = [data[i:i+cuts] for i in range(0,len(data),cuts)]\n",
    "    return final_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitches = makeBatches(training_data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156473\n"
     ]
    }
   ],
   "source": [
    "print(len(bitches[28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(batch,n):\n",
    "    window = [batch[i:i+n] for i in range(0,len(batch))]\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = bitches[1]\n",
    "w1 = sliding_windows(batch1,5)\n",
    "batch2 = bitches[2]\n",
    "w2 = sliding_windows(batch2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1 output\n",
    "training_sequences = {}\n",
    "training_sequences['Batch 1'] = [w1[i] for i in range(0,3)]\n",
    "training_sequences['Batch 2'] = [w2[i] for i in range(0,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Batch 1': [['the', 'rich', '.', '</s>', '<s>'], ['rich', '.', '</s>', '<s>', 'By'], ['.', '</s>', '<s>', 'By', '2018']], 'Batch 2': [['to', 'strike', 'Soleimani', ',', 'who'], ['strike', 'Soleimani', ',', 'who', 'was'], ['Soleimani', ',', 'who', 'was', 'visiting']]}\n"
     ]
    }
   ],
   "source": [
    "print(training_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Bengio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in pickle file for vocab dict\n",
    "import pickle\n",
    "\n",
    "file = open('Data/trainingDictPickle1_group1.pkl','rb')\n",
    "vocab_dict = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self, vocab_dict):\n",
    "        self.window_size = 5\n",
    "        self.num_batches = 30\n",
    "\n",
    "        self.vocab_size = len(vocab_dict)\n",
    "\n",
    "        self.hidden_units = 50\n",
    "        self.embeddings_dim = 60\n",
    "        self.num_epochs = 20\n",
    "\n",
    "        self.learning_rate = 0.5\n",
    "\n",
    "        self.gpu_mem = 0.25\n",
    "\n",
    "        self.tf_precision = tf.float32\n",
    "        self.np_precision = np.float32\n",
    "\n",
    "        self.init_scale = 0.5\n",
    "        self.max_grad = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, params=Parameters(vocab_dict)):\n",
    "        #initialize input and output variables\n",
    "        self._y = tf.placeholder(dtype=params.tf_precision,shape=(params.num_batches, params.vocab_size),name=\"Y\")\n",
    "        self._x = tf.placeholder(tf.int32,shape=(params.num_batches, params.window_size),name=\"X\")\n",
    "        #word features/embeddings\n",
    "        self.C = tf.Variable(tf.truncated_normal(shape=(params.vocab_size, params.embeddings_dim),mean=-1,stddev=-1),dtype=params.tf_precision,name=\"C\")\n",
    "        #projection to output weight\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(params.vocab_size, (params.window_size) * params.embeddings_dim)),dtype=params.tf_precision,name=\"W\")\n",
    "        #hidden layer weight and bias\n",
    "        self.H = tf.Variable(tf.random_normal(shape=(params.hidden_units, (params.window_size) * params.embeddings_dim)),dtype=params.tf_precision,name=\"H\")\n",
    "        self.d = tf.Variable(tf.random_normal(shape=(params.hidden_units,)),dtype=params.tf_precision,name=\"d\")\n",
    "        #hidden layer to output weight and bias\n",
    "        self.U = tf.Variable(tf.random_normal((params.vocab_size, params.hidden_units)),name=\"U\",dtype=params.tf_precision)\n",
    "        self.b = tf.Variable(tf.random_normal(shape=(params.vocab_size, )),dtype=params.tf_precision,name=\"b\")\n",
    "        #do calculations\n",
    "        # y = b + Wx + Utanh(d + Hx)\n",
    "        # x = (C(w(t-1)), C(w(t-2), ..., C(w(t-n+1))), n == window_size\n",
    "        with tf.name_scope('Projection_Layer'):\n",
    "            x  = tf.nn.embedding_lookup(self.C, self._x) # (batch_size, window_size-1, emb_dim)\n",
    "            x  = tf.reshape(x, shape=(params.num_batches, (params.window_size) * params.embeddings_dim))\n",
    "        with tf.name_scope('Hidden_Layer'):\n",
    "            Hx = tf.matmul(x, tf.transpose(self.H)) # (batch_size, hidden_size)\n",
    "            o  = tf.add(self.d, Hx) # (batch_size, hidden_size)\n",
    "            a  = tf.nn.tanh(o)  # (batch_size, hidden_size)\n",
    "        with tf.name_scope('Output_Layer'):\n",
    "            Ua = tf.matmul(a, tf.transpose(self.U)) # (batch_size, vocab_size)\n",
    "            Wx = tf.matmul(x, tf.transpose(self.W)) # (batch_size, vocab_size)\n",
    "            y_hat  = tf.nn.softmax(tf.clip_by_value(tf.add(self.b, tf.add(Wx, Ua)), 0.0, 10)) # (batch_size, vocab_size)\n",
    "    #2 different ways to minimize loss/cost\n",
    "        with tf.name_scope('Cost'):\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=self._y,logits=y_hat))\n",
    "            self.perplexity = tf.exp(self.cost)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(params.learning_rate).minimize(self.cost)\n",
    "    #loss function defined from github repo\n",
    "    '''\n",
    "        with tf.name_scope('Loss'):\n",
    "            onehot_tgt = tf.one_hot(tf.squeeze(self._y), params.vocab_size)  # (batch_size, vocab_size)\n",
    "            loss = -1 * tf.reduce_mean(tf.reduce_sum(tf.log(y) * onehot_tgt, 1)) # 乘 -1 -> maximize loss\n",
    "            print(loss)\n",
    "        \n",
    "        optimizer = tf.train.AdagradOptimizer(params.learning_rate).minimize(loss)\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Windows(batch, window_index, params):\n",
    "    x_window = batch[window_index:window_index + params.window_size]\n",
    "    y_targets = np.zeros(params.vocab_size)\n",
    "    #update y_targets according to each new predicted word in the sliding window\n",
    "    y_targets[batch[window_index + params.window_size]] = 1\n",
    "    return x_window, y_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,params,integer_batches):\n",
    "    #initialize and do GPU stuff\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    \n",
    "    #get lists to hold perplexity and cost graphs\n",
    "    perplexity_history = []\n",
    "    cost_history = []\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True)) as sess:\n",
    "        initializer = tf.global_variables_initializer()\n",
    "        initializer.run()\n",
    "        step = 0\n",
    "        #iterate through epochs\n",
    "        for epoch in range(params.num_epochs):\n",
    "            window_index = 0\n",
    "            #feed in each sliding context window\n",
    "            while window_index < len(integer_batches[0]) - params.window_size - 1:\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "                for batch in integer_batches:\n",
    "                    x_window, y_targets = get_Windows(batch,window_index,params)\n",
    "                    x_batch.append(x_window)\n",
    "                    y_batch.append(y_targets)\n",
    "                #run iteration of batches in the model\n",
    "                cost, perplexity, deez_nutz = sess.run([model.cost,model.perplexity, model.optimizer], feed_dict = {model._x:x_batch, model._y:y_batch})\n",
    "#                 if step % 1000 == 0:\n",
    "                perplexity_history.append(perplexity)\n",
    "                cost_history.append(cost)\n",
    "                window_index += 1\n",
    "                step += 1\n",
    "    return perplexity_history, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Brown Corpus/bc_unbatched.pkl','rb')\n",
    "brown_batches = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_vocab = set([tok for tok in brown_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, test\n",
    "brown_train = brown_batches[:800000]\n",
    "brown_validation = brown_batches[800000:1000000]\n",
    "brown_test = brown_batches[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_maker(lst):\n",
    "    a = {val : idx + 1 for idx, val in enumerate(lst)}\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_vocab_dicks_in_my_mouth = dict_maker(brown_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_train_int = [brown_vocab_dicks_in_my_mouth[tok] for tok in brown_train]\n",
    "brown_val_int = [brown_vocab_dicks_in_my_mouth[tok] for tok in brown_validation]\n",
    "brown_test_int = [brown_vocab_dicks_in_my_mouth[tok] for tok in brown_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on brown\n",
    "brown_train_batches_int = makeBatches(brown_train_int,30)\n",
    "brown_val_batches_int = makeBatches(brown_val_int,30)\n",
    "brown_test_batches_int = makeBatches(brown_test_int,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_params = Parameters(brown_vocab_dicks_in_my_mouth)\n",
    "brown_model = Model(params=brown_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 9.3 µs\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "brown_train_perplexity_history, brown_train_cost_history = run_model(brown_model,brown_params,brown_train_batches_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
